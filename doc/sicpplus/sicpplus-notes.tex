% !TEX TS-program = arara
% arara: xelatex: { synctex: on, options: [-halt-on-error] } 
% arara: biber
% % arara: texindy: { markup: xelatex }
% %% arara: makeglossaries
% % arara: xelatex: { synctex: on, options: [-interaction=batchmode, -halt-on-error] }
% % arara: xelatex: { synctex: on, options: [-interaction=batchmode, -halt-on-error]  }
% % arara: clean: { extensions: [ aux, log, out, run.xml, ptc, toc, mw, synctex.gz, ] }
% % arara: clean: { extensions: [ bbl, bcf, blg, ] }
% % arara: clean: { extensions: [ glg, glo, gls, ] }
% % arara: clean: { extensions: [ idx, ilg, ind, xdy, ] }
% % arara: clean: { extensions: [ plCode, plData, plMath, plExercise, plNote, plQuote, ] }
%-----------------------------------------------------------------
\documentclass[11pt]{PalisadesLakesBook}
% \geomHDTV
% \geomLandscape
\geomHalfDTV
\geomPortraitOneColumn
%-----------------------------------------------------------------

%\AsanaFonts % misssing \mathhyphen; less on page than Cormorant/Garamond
%\CormorantFonts % light, missing unicode greek
\EBGaramondFonts % fewest pages
%\ErewhonFonts
%\FiraFonts % tall lines, all sans, much less per page, missing \in?
%\GFSNeohellenicFonts 
%\KpFonts
%\LatinModernFonts
%\LegibleFonts
%\LibertinusFonts
%\NewComputerModernFonts
%\STIXTwoFonts
%\BonumFonts % most pages
%\PagellaFonts
%\ScholaFonts
%\TermesFonts
%\XITSFonts

%-----------------------------------------------------------------
\togglefalse{plMath}
\togglefalse{plCode}
\togglefalse{plData}
\togglefalse{plNote}
\togglefalse{plExercise}
\togglefalse{plQuote}
\togglefalse{printglossary}
\togglefalse{printindex}
%-----------------------------------------------------------------
\title{Notes on\\
 SICP,\\
  SICM,\\
   Functional Differential Geometry,\\ 
 Software Design for Flexibility, \\
 etc.}
\author{John Alan McDonald 
(palisades dot lakes at gmail dot com)}
\date{draft of \today}
%-----------------------------------------------------------------
\begin{document}
\maketitle
\PalisadesLakesTableOfContents{7}
%-----------------------------------------------------------------
\def\sharedFolder{../../shared/}
%-----------------------------------------------------------------
\begin{plSection}{Introduction}

Various works of Abelson, Sussman, et al.
 
Partially notes on reading; 
partially my own work-in-progress analysis 
and implementation in 
Clojure~\cite{
EmerickCarperGrand:2012:ClojureProgramming,
FogusHouser:2011:JoyOfClojure,
Halloway:2009:Clojure,
Hickey:2012:Clojure,
Rathore:2011:Clojure,
VanderhartSierra:2009:Clojure,}.

\citeAuthorYearTitle{HalfantSussman:1987:AbstractNumerical}

\citeAuthorYearTitle{AbelsonSussman:1996:SICP}

\citeAuthorYearTitle{SussmanWisdom:2013:FunctionalDifferentialGeometry}

\citeAuthorYearTitle{SussmanWisdom:2015:SICM2}

\citeAuthorYearTitle{HansonSussman:2021:SDFF}

%-----------------------------------------------------------------
\end{plSection}%{Introduction}
%-----------------------------------------------------------------
\begin{plSection}{Reading}
%-----------------------------------------------------------------
\begin{plSection}{\citeAuthorYearTitle{HansonSussman:2021:SDFF}}
%-----------------------------------------------------------------
\begin{plSection}{Forward (Guy Steele)}

Describes book as \emph{master class}, not tutorial.

Argues for bundling code plus data as \emph{closures}. 
Also \emph{generic functions}.

Not, perhaps, the clearest such argument, but how much can you do
in a 2 pages forward?

My argument would go something like:
Data is just bits, meaningless on its own.
The code that manipulates those bits determines their 
\emph{meaning}.
The farther the ``distance'' (in some sense) 
between code an data, 
the higher the likelihood of confusion,
of misinterpreting bits. 

\end{plSection}%{Forward (Guy Steele)}
%-----------------------------------------------------------------
\begin{plSection}{Preface}

One goal is to modify by addition, 
without changing existing code.

Begins talking about a very questionable analogy 
to biological systems.
Possibly a fallacy inherited from traditional AI.
Particularly ironic in the middle of a pandemic.

Something I believe:
\begin{plQuote}
{\citeAuthorYearTitle[p~xiii]{HansonSussman:2021:SDFF}}{}
We have often programmed ourselves into corners
and had to expend great effort to escape from those corners.
We have accumulated enough experience to feel that we can
identify, isolate, and demonstrate strategies
that we have found to be effective for building large systems
that can be adapted for purposes 
that were not anticipated in the original design. {\ldots}
\end{plQuote}
However, they may be over promising in some sense.

Sometimes, the best choice is starting over.
There are different levels of ``starting over'':
for example, complete re-design, 
re-implementing a mostly-the-same API, {\ldots}

My own experience is that, when having a choice
between starting from scratch and fixing the existing code,
the times I chose to start over were never a mistake,
and many, if not most, of the times I chose to ``fix'' existing
code turned out to cost more time than starting over would have.
I think I have always been more likely than most 
                to advocate starting clean,
and in my experience I've been too conservative in that direction.
The cause may be over-estimating the cost of something new
relative to the costs of maintaining/updating something that
already exists. THe reasons for that may have something to do
with the difficulty of associating costs to a design decision
that was made long ago.

Plus fear of the unknown: legacy code whose authors have vanished,
and no one present fully understands what it is doing or why.
The fear is that there is some lost lesson in the existing
code that will have to be painfully relearned in anything new.

We will see if the book has any to say about making such choices.

\end{plSection}%{Preface}
%-----------------------------------------------------------------
\begin{plSection}{Acknowledgements}
\begin{plQuote}
{\citeAuthorYearTitle[p~xiix]{HansonSussman:2021:SDFF}}{}
In many ways this book is an advanced sequel to SICP.
\end{plQuote}

Sussman acknowledges discussions (in graduate school?)
with Minsky and fellow students---possibly a source for the
biologically motivated old-style AI ideas that appear.
\end{plSection}%{Acknowledgements}
%-----------------------------------------------------------------
\begin{plSection}{1 Flexibility in nature and design}
%-----------------------------------------------------------------
\begin{plSection}{Summary of my reaction}

I find this chapter disappointing.

I think the fundamental flaw is using 
inappropriate analogies to other problem domains,
eg, (physical building) architecture
and, especially, evolution, 
to justify their ideas about software artifact design
and construction,
rather than arguing on first principles.
This is some version of the ``false analogy'' 
fallacy~\cite{wiki:ArgumentFromAnalogyFalse},
or perhaps the
``appeal to authority'' fallacy~\cite{wiki:ArgumentFromAuthority},
where the ``authority'' isn't talking about the problem at hand, 
and is not so clearly an ``authority'' in their own domain either.

These and similarly fallacious reasoning are common
in books about software design strategies, best practices,
philosophies, etc.

In software design, or any design problem,
it is difficult to usefully characterize what ``better'' means,
and hard to demonstrate to a skeptical observer that one
approach is ``better'' than another.
Hard enough to do with a reasonably objective observer,
and so much worse in areas like software design,
where people are heavily invested in particular technologies,
in time, money, and emotion.

I think this is a reason that so many fall into two rough classes
of fallacious reasoning. 

One is the appeal to false authority/analogy so prevalent in this 
chapter. 

In the perhaps more common version of this, the authors set 
themselves, or some other software ``guru'' as the authority, 
usually accompanied by oracular pronouncements left to the reader
to interpret.
This book is thankfully free from that.

The next most common is to appeal to some authority/analogy
from some other problem domain,
about which neither the reader nor the author know much.
The advantage of this, as (false) propaganda, 
is that the reader might doubt the pronouncements
of some ``guru'' that are falsified by their own experience,
but would be less confident questioning, for example,
dubious assertions about how evolution works.

The second class of fallacy is some variation on false 
quantification. 
In other words, pick some single criterion that is
easy to measure, easy to compare, and, ideally,
provides a total ordering. 
THe classic example is thinking more money is always better;
easy to tell that job A pays more than job B;
hard to tell which one really makes your life ``better''.

This chapter is essentially defending their ideas about software
design from fallacy type (2),
but they could do better.

They point out the error of premature optimization,
but miss the fact that start up costs are easier to measure
and, because they are closer in time, easier to attribute to
design choices. 
Long term maintenance costs are harder to measure and
associate with particular design choices.

The other problem with early optimization is that you don't
really understand what the code needs to do until you try to
use it in a real situation.

They are missing, what I think is one of the strongest arguments
in favor of their approach---the need for 
\emph{experimental/exploratory programming}.
\begin{itemize}
  \item Situations where you can fully specify what you need
  ahead of time---where you even understand what's 
  possible---are extremely rare.
  \item The faster and further you explore possibilities,
  the better the final result.
  \item If you don't do this, you are giving up one of the
  biggest advantages software has over other kinds of engineering:
  it is really easy to try different things.
  In this, I think there is a lot in common with math research.
  Hit a dead end? Erase the blackboard (delete files) 
  and start over.
  In physical engineering, say airplane design, you would have
  to scrap a $10^{6}$ dollar prototype and build another
  (and another and another {\ldots}).
  
  \item Sometimes people advocate 
  
  \item There is no final result. Context keeps changing.
  
\end{itemize}
Hanson and Sussman use the word \emph{evolvable}, 
to mean something similar, but not exactly the same,
and their use is confused by the false analogy to biology.
Evolution has no goal. 
Exploratory programming is about figuring out what the goal 
of the code can and should be.

Missing:
Software as written language; 
say just enough; avoid s/he problem.
Math (another written language) uses ambiguity
and implied context to reduce complexity,
to make (symbolic) calculations feasible,
within a few pages, blackboards, mortal mortal memory.
Is something similar possible or good in software? 

\end{plSection}%{Summary of my reaction}
%-----------------------------------------------------------------
\begin{plSection}{Initial text in ch 1}
They mention both screw fasteners and digital computers
as examples  of ``general purpose inventions'',
without saying what ``general purpose'' means.
There is obviously some limitation,
since a digital computer isn't very useful for holding two pieces 
of metal together, and a screw fastener won't help much in, say,
calculating your taxes. 
But the analogy really falls apart if you stop for a moment to
think about the fact that there probably on the order of 
$10^{5}\text{--}10^{6}$ different types of screw fasteners,
some  of which are highly optimized for specific applications,
and none of which cover all possible applications.
And the same is true, more or less, for digital computers,
though the number of distinct types is likely fewer.

I'm sure they know better, 
but their discussion suggests
specialized vs general purpose
and success vs failure are both binary.
Any tool will have some domain of tasks where it can be used
with varying degrees of success.
Possibly the argument here should really be about 
how (and when or if) making things more general increases
the probable degree of success. 

Possibly a better way to approach this
would be to talk about the need for humility in specifying
what a piece of software (or any tool) will be used for.
Enlarging the domain of applicability, in the right ways,
increases the chances that it will be useful when circumstances 
change, and, more important, 
when the first real use exposes all sorts of things 
you simply failed to think of ahead of time.
This is related in some ways to the ``Postel's law''
mentioned later, which I would re-word as:
functions should have large domains and small codomains.
But I think it's not really the same thing
(\textbf{TODO:} need a better word for problem ``domain"
that distinguishes it from function ``domain".
And examples would be nice.)

%-----------------------------------------------------------------
\begin{plSection}{Additive programming}
\label{sec:AdditiveProgramming}

Not crazy about the name.

Code can be flexible if it permits updates by \emph{replacing}
parts, not just \emph{adding} parts.
Common case: 
replace old implementation with (almost) equivalent 
higher performance one, and discard the slow version to ensure
it isn't invoked accidentally. 

In either case, proper abstraction makes it less likely
an update will break something that currently works.

What they advocate (p~2--3)
\begin{itemize}
  \item minimize assumptions about what a program will do.
  \item just-in-time decisions instead.
  \item whole more than sum of parts (this is almost automatic,
  depending on the meaning of ``sum''.)
  \item parts with separate concerns. (should really be groups of
  parts that share concerns, separate different groups.
  contradicts shared apis below.)
  \item minimize interactions (which contradicts to some degree
  wanting more than the sum of parts)
  \item parts ``simple and general'' 
  (but what does that mean? given two designs, how do you
  tell which is simpler and more general?)
  \item enlarge the (function) domain of ``acceptable'' inputs
  (which contradicts ``simple and general''?)
  \item reduce the codomain of possible outputs. 
  \item families of parts with same api (possibly on both sides
  of the api) (contradicts separate concerns, since sharing
  an api means sharing ``concerns'')
\end{itemize}

Postel's Law: Advocates robustness in the sense of
(1) accepting large domain of inputs
and (2) producing a small ``range of outputs of a part'' 
(codomain).
Not sure I believe this.
Depends on what ``accepting'' means in (1).
Often the right choice is to clearly reject unacceptable inputs
as soon as possible.
For example, if somebody asks for $\sqrt{\text{blue}}$
you generally don't want to quietly return \texttt{0x00000F}.

More concrete recommendations (p~3--5):
\begin{itemize}
  \item \emph{domain specific languages}, 
  which they equate to a family
  of ``mix-and-match parts''. I don't think that's 
  what most people mean by DSL, rather something more like
  syntactic sugar to make it easier to type common expressions
  in a problem domain. I've never been a fan of that notion of
  DSLs. Needing one is a symptom that you haven't gotten the
  abstractions (the mix-and-match parts) right. And it tends
  to create arbitrary syntactic barriers resulting in 
  ``impedance mismatch''.
  \item \emph{generic dispatch}. They require methods (``handlers'')
  to be associated with ``disjoint sets of arguments'', 
  which I don't think is always the right choice.
  They don't assume method choice is determined by class
  inheritance (good!).
  \item \emph{layer} data and procedures. Not at all clear what 
  that means (yet). Something about metadata.
  Example of numerical data with units.  
  \item combine multiple sources of (independent) 
  \emph{partial information}. 
  Also not clear what it means (yet).
  Example of combining parallax and brightness, etc., to estimate
  distance to star. 
  Not clear what's partial about this.
  Sounds like algorithms rather than
  program design techniques, and the idea that this can be done
  in an application-independent way, without careful
  testing and tuning in each case, seems naive.
  We'll see {\ldots}.
  \item \emph{degeneracy}. again not clear from brief description.
  They say that its' ``dual'' to partial
  information, but actually sounds like the same thing.
  Perhaps the idea is multiple procedures for computing the same
  thing, rather than multiple sources of data.
  (I really hate it when people use ``dual'' with specifying
  what they mean, in a way that seems like they just
  think it sounds cool, 
  and haven't thought thru what the point is.)
\end{itemize}

Last couple paragraphs on p~5:
Mentions upfront cost of flexible design vs
lifetime maintenance.
I think this could be strengthened.
A point that could be added is that 
it is easier to see the effect of design decisions 
on the cost/time of the initial implementation,
and harder to connect them to maintenance costs, 
often years later, with no one around who even remembers 
what those choices were. 

\end{plSection}%{Additive programming}
%-----------------------------------------------------------------
\end{plSection}%{Initial text in ch 1}
%-----------------------------------------------------------------
\begin{plSection}{1.1 Architecture of computation}

``A metaphor from architecture may be illuminating for the kind
of system that we contemplate.''

My appeal-to-false-authority alarms are going off.
The appeal to physical architecture, pattern languages, etc.,
is commonplace in writings on software design,
but I have always found it suspect.
The idea that a field 
where the constraints and degrees of freedom
are so fundamentally different should be imitated 
by software design is questionable at best.
As one who has had to deal with many heavily designed
and consequently dysfunctional buildings,
I find the idea that architects are actually good at what they do,
in any real sense, dubious.
See for example \citeAuthorYearTitle{Rybczynski:1986:Home},
which is a reference I just happen to have read some years ago.
(\textbf{TODO:} quote the forward?)

The remainder of the section is a confusing description 
of the term ``parti''.
And I don't think there is anything that wouldn't have been 
clearer if given directly in terms of software,
without the appeal to (physical) architecture as a model. 

\end{plSection}%{Sec~1.1 Architecture of computation}
%-----------------------------------------------------------------
\begin{plSection}{1.2 Smart parts for flexibility}

Starts with discussing the difficulty of specification
in the face of complexity. 

But, how do you measure complexity?
Example: how do you specify that a program
``plays a \emph{good} game of chess''?
But the issue there isn't complexity.
Possibly it is intrinsic ambiguity: disagreement about what
``good'' means.
I'm not sure that chess is the best example of that.
Most would agree winning is better than losing.
I suppose you could get some ambiguity out of lack of
total ordering: 
program A might (usually) beat program B,
which might (usually) beat program C, 
which might (usually) beat program A {\ldots}.

Then another appeal-to-false-authority,
in this case, with a claim the biological systems
are inherently robust and adaptable
(ironic in the middle of a pandemic).
Not clear at this point exactly what that implies for software
design.

``One idea is that biological systems use contextual signals
that are informative rather than imperative.
There is no master commander saying what each mart must do;
instead the parts choose their roles based on their surroundings.''

They seem to be advocating some communicating agents model
of computation.
The point is lost: at one point they are arguing for
``smart parts'', but also ``simpler'' and ``more general'',
all of which conflict. depending on the meaning of those
undefined terms. 
The analogy to biological systems falls apart with another
moment's thought: 
individual cells might be considered ``general'',
at least when they are stem cells,
but I don't think many would accept calling them ``simple''
or ``smart''.

This is followed by another false analogy to social systems:
democracy is better than autocracy, 
so software should avoid central controller designs.
I think there are good reasons for avoiding 
centralized synchronization,
and it doesn't need an appeal to democracy to justify it.
If anything the argument could go in the opposite direction:
it's easier to understand why synchronization and deadlock
are problems in software systems, 
which might help understand when similar designs 
might or might not be a good idea in social systems.
 
%-----------------------------------------------------------------
\begin{plSection}{Body plans}

``All vertebrates have essentially the same body plan.''

False authority alarm! 
They assume, without any evidence or argument,
that this ia a good thing, 
rather than just a contingent effect of 
evolution and constraints of biological development.
Rather than being an example of flexible design,
the shared body plan of vertebrates
is as or more likely evidence of natural selection
``painting itself into a corner''.

They then turn to design of radio receivers as another analogy.
The problem with this analogy is that all radio receivers
are doing pretty much the same thing,
and, even in this specialized case, 
it appears that there are a number of distinct ``body plans''.

They eventually get around to ``combinators''
and ``combinator languages''.
I've never been crazy about the terminology;
to me it makes something that's simple and obvious 
seem more difficult
and obscure than it needs to be.

The actual idea is good and important:
Systems are built out of things we think of as more-or-less
independent components;
the structures that combine components 
are themselves components,
(more-or-less) independent of each other 
and the things they combine,
and they can be further combined, ad infinitum {\ldots}.

I don't think you need any of the analogies to explain this
or justify it; I think they just get in the way.
And biological system don't have the same elegant recursive
structure, so if you took that as you model, 
you would miss something critical.

``Biological systems are universal in that each component can,
in principle, act as any other component. [p~11]''
This is just flat out false. 
Not even really true for stem cells, 
even at early stages of development,
and certainly not true later.

(And what's the implication for software?)

Section finishes by proposing an \emph{evaluator} as 
analog to stem cells:
``An evaluator takes a description of some computation
to be performed and input to that computation.
It produces the outputs that would arise if we passed the inputs
to a bespoke component that implemented the desired computation.
In computation we have a chance to pursue the powerfully
flexible strategy of embryonic development.
We will elaborate on the use of evaluator technology in chapter 5.''

This has so many problems, it's hard to know where to begin.
There are the usual, and unnecessary, appeal-to fallacies.
Perhaps more important, how is 
``a description of some computation to be performed"
different from 
``a bespoke component''? 
The stem cell analogy doesn't work, and obscures whatever
advantages and disadvantages an evaluator strategy might have.
THere are many stem cells,
and each re-configures itself
into something distinct and more specialized, 
in a one-way process.
The (almost always single) evaluator doesn't change, 
it just gets different computations to perform.
My guess is that the advantages are related to delaying
certain decisions about how to perform a particular computation,
following the general principle (not from biology or architecture)
that delaying a decision often gives you 
more information that can be used to optimize it.
Of course, delay isn't always better; 
sometimes waiting removes options.

\end{plSection}%{Body plans}
%-----------------------------------------------------------------
\end{plSection}%{1.2 Smart parts for flexibility}
%-----------------------------------------------------------------
\begin{plSection}{1.3 Redundancy and degeneracy}



Problems:
\begin{itemize}
  
  \item ``One of the characteristics of biological systems
is that they are redundant. 
Organs such as the liver and kidney are highly \emph{redundant}:
there is vastly more capacity than is necessary to do the job,
so a person missing a kidney or part of a [sic] liver suffers
no obvious incapacity.
Biological systems are also highly \emph{degenerate}:
there are usually many ways 
to satisfy a given requirement.''[p~12]
Usual unnecessary, false analogy.
  There are many obvious, better analogies, like airplane design.
  
  \item ``\emph{highly} redundant'',
  ``\emph{vastly} more capacity'' [emphasis mine]:
  Unless you could get by with, say,  less than $\frac{1}{10}$ 
  of a liver and kidney, I wouldn't say they are ``highly'' or
  ``vastly'' redundant.
  
  \item''\emph{degenerate}'': A few minutes looking at 
  dictionaries online finds no definition that matches this use.
  A guess is that this use is like ``dual'' earlier---a math-y
  sounding word that they haven't defined or thought thru
  carefully. What they mean is actually ``redundant'',
  and I guess they are trying to distinguish two kinds 
  of redundancy: excess capacity and and alternate mechanisms.
  
  \item They go on to describe the genetic code as ``degenerate'',
  which is yet another, distinct, non-standard, undefined meaning. 
  In this case, the issue is that
  the mapping from DNA to protein is not $\OneToOne$,
  multiple points in DNA space map to the same protein.
  They then confuse the many-to-one-ness of the mapping
  with a different, and not so obviously true, ``continuity" 
  property:
  small changes to DNA (often) result 
  in small changes in cell function.
  
  \item ``The theoretical structure of physics is deeply 
\emph{degenerate}.
For example, problems in classical mechanics can be approached
in multiple ways.''[p~12, emphasis mine]
This use is closer to their ``definition'',
but missing a key point. 
A better way to look at these things is to formulate 
the problem at the right level of abstraction,
and consider the choice between 
multiple representations/parameterizations of that abstraction
a computational detail.
(I think this may be why I never got very far 
in the first edition of SICM.)
For example:
\begin{plQuote}
{\citeAuthorYearTitle{MacLane:1954:Courses}}
{maclane:vspace}
Throughout these courses the infusion of a geometrical
point of view is of paramount importance. A vector
is geometrical; it is an element of a vector space, defined
by suitable axioms—whether the scalars be real numbers or
elements of a general field. A vector is not an n-tuple of
numbers until a coordinate system has been chosen. Any
teacher and any text book which starts with the idea that vectors
are n-tuples is committing a crime for which the proper
punishment is ridicule. The n-tuple idea is not ‘easier,’ it is
harder; it is not clearer, it is more misleading. By the same
token, linear transformations are basic and matrices are their
representations\ldots
\end{plQuote}

\item ``Engineered systems may incorporate some redundancy 
{\ldots}.
But they almost never incorporate degeneracy {\ldots},
except as a side effect of designs that are not optimal.''
Doesn't take much effort to show this is false.
Airplanes and nuclear power plants, among many other cases,
as a matter of course, incorporate many ``degenerate'' components,
where ``degenerate'' means 
``redundant distinct mechanisms for each critical task''.

\end{itemize}

At the end of this section, they refer to 
``combining partial information'' which will be covered in ch 7.
This confused discussion of ``redundancy'' and ``degeneracy''
is at best distantly related, and doesn't touch 
on the key issue: How do you combine?
Maybe ch 7 will be better {\ldots}.

\end{plSection}%{1.3 Redundancy and degeneracy}
%-----------------------------------------------------------------
\begin{plSection}{Exploratory behavior}

This section is similar to the preceding ones.
Inappropriate biological analogies that misunderstand the biology
and obscure the possibly valuable point.

The real idea is to compute something by searching a domain.
They seem to assume search must be random,
but of course that need not be so.

Figure 1.2 illustrates two possibilities:
(1) generate and test, looping until the test returns success,
and (2) generate and filter, without feedback.
I suspect that there is a better, more general picture,
related to walking around a domain,
using data accumulated on previous samples to determine
the next step.

They finally mention ``backtracking'', to be discussed 
further in ch 4 and 5.

\end{plSection}%{Exploratory behavior}
%-----------------------------------------------------------------
\begin{plSection}{1.5 The cost of flexibility}

Better than the previous sections,
because they mostly drop 
the appeals to false authority/analogy fallacies.

Starts by saying general and evolvable systems,
 that use the techniques described (very poorly!) 
 in the previous systems, are expensive.
Not clear to me that that is true, at least not always,
and nothing concrete to justify it.

``Part of the problem is that we are thinking abut cost
in the wrong terms.''[p~17]
Good as far as it goes, but I think they are missing something
important.

A fundamental problem in software design, or any design problem,
is that it is hard to usefully characterize what ``better' means,
and hard to demonstrate to a skeptical observer that one
approach is ``better'' than another.
Hard enough to do with a reasonably objective observer,
and so much worse in areas like software design,
where people are heavily invested in particular technologies,
in time, money, and emotion.

I think this is a reason that so many fall into two rough classes
of fallacious reasoning. 

One is the appeal to false authority/analogy so prevalent in this 
chapter. 
In the perhaps more common version of this, the authors set 
themselves as the authority, 
usually accompanied by oracular pronouncements left to the reader
to interpret.
This book is thankfully free from that.
The next most common is to appeal to some authority/analogy
from some other problem domain, about which 
neither the reader nor the author know much.

The second class of fallacy is some variation on false 
quantification. 
In other words, pick some criterion that is
easy to measure, easy to compare, and, ideally,
provides a total ordering. 
THe classic example is thinking more money is always better;
easy to tell that job A pays more than job B;
hard to tell which one really makes your life ``better''.

This chapter is essentially defending their ideas about software
design from fallacy type (2),
but they could do better.

They point out the error of premature optimization,
but miss the fact that start up costs are easier to measure
and, because they are closer in time, easier to attribute to
design choices. 
Long term maintenance costs are harder to measure and
associate with particular design choices.

The other problem with early optimization is that you don't
really understand what the code needs to do until you try to
use it in a real situation.

There is a subsection titled ``The problem with correctness''.
I agree with the conclusion, but I don't think their arguments
are very good.

``We assert this discipline [requiring proofs of correctness]
makes systems more brittle''.
But they don't offer much to support this assertion.

The fundamental problem with achieving ``correctness''
by proving a program meets a specification is:
How do you know the specification is correct?
In some sense, you are really just re-writing the program
in a different language.
At most, you are removing some distracting details,
and specifying only results, rather than how to get there.
It is, in any case, restricted to tasks  where a person can
read and verify the specification by eye.

\end{plSection}%{1.5 The cost of flexibility}
%-----------------------------------------------------------------
\end{plSection}%{Ch 1: Flexibility in nature and design}
%-----------------------------------------------------------------
\begin{plSection}{2 Domain Specific Languages}

As I mentioned in \cref{sec:AdditiveProgramming},
their description of ``DSL'' doesn't match 
what the term suggests to me
(and, I think, to most software developers):
restrictive syntactic sugar that reduces 
the unnecessary baroque boilerplate code, 
that results from choosing a bad base language.

In \cref{sec:AdditiveProgramming},
they describe a DSL as a family
of ``mix-and-match parts''.
Here, they call it  
``an abstraction in which the nouns and verbs of the language
are directly related to the problem domain.''
They don't say what they mean by ``nouns'' and ``verbs'',
or give any reference.

A quick search shows that this is a popular topic for web rants,
But I haven't found anything very insightful.
It looks like yet another misleading metaphor/simile
that lets people think they've gotten some easy insight,
when, in fact, it's just wrong.
Functions aren't verbs and objects aren't nouns,
even superficially.
And many natural languages don't  have clearly distinguished 
nouns and verbs (eg Chinese and English!).

(I'm not sure where the ``noun/verb $=$ object/function'' 
metaphor originated,
maybe \citeAuthorYearTitle{Yegge:2006:Nouns}?)

%-----------------------------------------------------------------
\begin{plSection}{2.1 Combinators}
%-----------------------------------------------------------------
\begin{plSection}{2.1.1 Function combinators}
%-----------------------------------------------------------------
\begin{plSection}{Arity}
\end{plSection}%{Arity}
%-----------------------------------------------------------------
\begin{plSection}{Multiple values}
\end{plSection}%{Multiple values}
%-----------------------------------------------------------------
\begin{plSection}{A small library}
\end{plSection}%{A small library}
%-----------------------------------------------------------------
\end{plSection}%{2.1.1 Function combinators}
%-----------------------------------------------------------------
\end{plSection}%{2.1 Combinators}
%-----------------------------------------------------------------
\end{plSection}%{2 Domain Specific Languages}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\end{plSection}%{\citeAuthorYearTitle{HansonSussman:2021:SDFF}}
%-----------------------------------------------------------------
\end{plSection}%{Reading}
%-----------------------------------------------------------------
\begin{plSection}{Implementation}
I am stretching the work ``implementation'' to cover both
software and a mathematical formulation of the problems.
%-----------------------------------------------------------------
\begin{plSection}{Foundation sketch}

Math from idealized countable computation.

Idea: base mathematics on an ideal (Turing-like) machine.
Then mapping to usable software is more-or-less mapping
the ideal machine to a realizable one.

End result is something like constructive analysis
with no more than countable infinity, if that.
The key spaces in the readings will be built out of 
some version of computable reals.

See:

\citeAuthorYearTitle{Feferman:1989:IsCantorNecessary}

\citeAuthorYearTitle[ch.~2 ``Is Cantor necessary?'']{Feferman:1998:LightOfLogic}

\citeAuthorYearTitle[ch.~12 ``Is Cantor necessary? (Conclusion)'']{Feferman:1998:LightOfLogic}

\citeAuthorYearTitle{Feferman:1992:ALittleBit}

\citeAuthorYearTitle[ch~14 ``Why a little bit goes a long way:
logical foundations of scientifically applicable mathematics'']{Feferman:1998:LightOfLogic}

%-----------------------------------------------------------------
\begin{plSection}{An ideal machine}
\begin{itemize}
  \item Turing machine~\cite{
  Turing:1936:Computability,
  Turing:1937:ComputabilityLambda,
  Turing:1938:ComputabilityCorrection},
  Lambda calculus, etc.,
  equivalent,
  but more ``convenient''.
  \item unbounded (but not infinite)
  \item deterministic (?)
  \item references with tagged values
  \item write-once memory (but maybe that's not ``convenient'')?
  \item Primitive values plus data structures built out of tagged
  references.
\end{itemize}
\end{plSection}%{An ideal machine}
%-----------------------------------------------------------------
\begin{plSection}{An ideal language}
Ideal (formal) language. Lambda calculus but more ``convenient''.

Math based on procedures (procedural functions) 
in the ideal language.

Everything must handle the possible of non-terminating procedures
(on some or all inputs).
\end{plSection}%{An ideal language}
%-----------------------------------------------------------------
\begin{plSection}{(Procedural) Functions} 

A set is a procedure that returns true or false for any input
value.
As opposed to axiomatic set theory.
I think this eliminates the set paradoxes
that led to the ``crisis in mathematics'' circa 1900~\cite{
Feferman:2000:ConstructivePredicativeClassicalAnalysis,
Ferreiros:2008:Crisis}.

A proof is a procedure that takes a set of axiom expressions
and returns another (according to some rules).

\end{plSection}%{(Procedural) Functions} 
%-----------------------------------------------------------------
\begin{plSection}{(Procedural) Sets} 

\end{plSection}%{(Procedural) Sets} 
%-----------------------------------------------------------------
\end{plSection}%{Foundation sketch}
%-----------------------------------------------------------------
\end{plSection}%{Implementation}
%-----------------------------------------------------------------
\BeginAppendices
\input{typesetting}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\end{document}
%-----------------------------------------------------------------
